{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   mnist_ae2.py   date. 7/4/2016\n",
    "#   \n",
    "#   Autoencoder tutorial code - trial of convolutional AE\n",
    "#\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from my_nn_lib import Convolution2D, MaxPooling2D\n",
    "from my_nn_lib import FullConnected, ReadOutLayer\n",
    "%matplotlib inline\n",
    "\n",
    "# Up-sampling 2-D Layer (deconvolutoinal Layer)\n",
    "class Conv2Dtranspose(object):\n",
    "    '''\n",
    "      constructor's args:\n",
    "          input      : input image (2D matrix)\n",
    "          output_siz : output image size\n",
    "          in_ch      : number of incoming image channel\n",
    "          out_ch     : number of outgoing image channel\n",
    "          patch_siz  : filter(patch) size\n",
    "    '''\n",
    "    def __init__(self, input, output_siz, in_ch, out_ch, patch_siz, activation='relu'):\n",
    "        self.input = input      \n",
    "        self.rows = output_siz[0]\n",
    "        self.cols = output_siz[1]\n",
    "        self.out_ch = out_ch\n",
    "        self.activation = activation\n",
    "        \n",
    "        wshape = [patch_siz[0], patch_siz[1], out_ch, in_ch]    # note the arguments order\n",
    "        \n",
    "        w_cvt = tf.Variable(tf.truncated_normal(wshape, stddev=0.1), \n",
    "                            trainable=True)\n",
    "        b_cvt = tf.Variable(tf.constant(0.1, shape=[out_ch]), \n",
    "                            trainable=True)\n",
    "        self.batsiz = tf.shape(input)[0]\n",
    "        self.w = w_cvt\n",
    "        self.b = b_cvt\n",
    "        self.params = [self.w, self.b]\n",
    "        \n",
    "    def output(self):\n",
    "        shape4D = [self.batsiz, self.rows, self.cols, self.out_ch]      \n",
    "        linout = tf.nn.conv2d_transpose(self.input, self.w, output_shape=shape4D,\n",
    "                            strides=[1, 2, 2, 1], padding='SAME') + self.b\n",
    "        if self.activation == 'relu':\n",
    "            self.output = tf.nn.relu(linout)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.output = tf.sigmoid(linout)\n",
    "        else:\n",
    "            self.output = linout\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "# Create the model\n",
    "def model(X, w_e, b_e, w_d, b_d):\n",
    "    encoded = tf.sigmoid(tf.matmul(X, w_e) + b_e)\n",
    "    decoded = tf.sigmoid(tf.matmul(encoded, w_d) + b_d)\n",
    "    \n",
    "    return encoded, decoded\n",
    "\n",
    "def encoding_CNN(x_inp, starting_channels=3):\n",
    "    conv00 = Convolution2D(x_inp, (64, 64), starting_channels, 4, \n",
    "                          (5, 5), activation='relu')\n",
    "    conv00_out = conv00.output()\n",
    "    \n",
    "    conv0 = Convolution2D(conv00_out, (64, 64), 4, 4, \n",
    "                          (3, 3), activation='relu')\n",
    "    conv0_out = conv0.output()\n",
    "    \n",
    "    pool0 = MaxPooling2D(conv0_out)\n",
    "    pool0_out = pool0.output()\n",
    "    \n",
    "    conv1 = Convolution2D(pool0_out, (32, 32), 4, 8, \n",
    "                          (3, 3), activation='relu')\n",
    "    conv1_out = conv1.output()\n",
    "    \n",
    "    pool1 = MaxPooling2D(conv1_out)\n",
    "    pool1_out = pool1.output()\n",
    "    \n",
    "    conv2 = Convolution2D(pool1_out, (16, 16), 8, 16, \n",
    "                          (3, 3), activation='relu')\n",
    "    conv2_out = conv2.output()\n",
    "    \n",
    "    pool2 = MaxPooling2D(conv2_out)\n",
    "    pool2_out = pool2.output()\n",
    "\n",
    "    conv3 = Convolution2D(pool2_out, (8, 8), 16, 16, (3, 3), activation='relu')\n",
    "    conv3_out = conv3.output()\n",
    "\n",
    "    pool3 = MaxPooling2D(conv3_out)\n",
    "    pool3_out = pool3.output()\n",
    "    \n",
    "    return pool3_out\n",
    "\n",
    "def discrim_model(img_inp):\n",
    "    dec_enc = encoding_CNN(img_inp, starting_channels=3)\n",
    "    \n",
    "    flatenned = tf.contrib.layers.flatten(dec_enc)\n",
    "    flatenned = tf.layers.dense(flatenned, 32, activation=tf.nn.relu)\n",
    "    d_pred = tf.layers.dense(flatenned, 1, activation=None)\n",
    "    \n",
    "    return d_pred\n",
    "\n",
    "def mk_nn_model(x, sentp=None, y=None, real_imgp=None, bs=8):\n",
    "    # Encoding phase\n",
    "    x_image = x #tf.reshape(x, [-1, 64, 64, 1])\n",
    "    if y==None:\n",
    "        y=x\n",
    "    \n",
    "    enc_inp = encoding_CNN(x_image)\n",
    "    \n",
    "    # at this point the representation is (16, 4, 4) i.e. 128*2-dimensional\n",
    "    \n",
    "    \n",
    "    flatenned = tf.contrib.layers.flatten(enc_inp)\n",
    "    if sentp!=None:\n",
    "        flatenned = tf.concat([flatenned, sentp],1)\n",
    "    flatenned = tf.layers.dense(flatenned, 128*2, activation=tf.nn.relu)\n",
    "    flatenned = tf.layers.dense(flatenned, 128*2, activation=tf.nn.relu)\n",
    "    \n",
    "    net = tf.reshape(flatenned, [-1, 4, 4, 16])\n",
    "    \n",
    "    # Decoding phase\n",
    "    conv_t1 = Conv2Dtranspose(net, (8, 8), 16, 16,\n",
    "                         (3, 3), activation='relu')\n",
    "    conv_t1_out = conv_t1.output()\n",
    "\n",
    "    conv_t2 = Conv2Dtranspose(conv_t1_out, (16, 16), 16, 8,\n",
    "                         (3, 3), activation='relu')\n",
    "    conv_t2_out = conv_t2.output()\n",
    "\n",
    "    conv_t3 = Conv2Dtranspose(conv_t2_out, (32, 32), 8, 4, \n",
    "                         (3, 3), activation='relu')\n",
    "    conv_t3_out = conv_t3.output()\n",
    "\n",
    "    conv_t35 = Conv2Dtranspose(conv_t3_out, (64, 64), 4, 4, \n",
    "                         (3, 3), activation='relu')\n",
    "    conv_t35_out = conv_t35.output()\n",
    "\n",
    "    conv_last = Convolution2D(conv_t35_out, (64, 64), 4, 3, (5, 5),\n",
    "                         activation=None)\n",
    "    decoded_raw = conv_last.output()\n",
    "\n",
    "    dec_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = decoded_raw, labels = y))\n",
    "    \n",
    "#     decoded = tf.reshape(decoded, [-1, 64*64])\n",
    "#     dec_cross_entropy = -1. *y *tf.log(decoded + 1e-30) - (1. - y) *tf.log(1. - decoded + 1e-30)\n",
    "#     dec_loss = tf.reduce_mean(dec_cross_entropy)\n",
    "    \n",
    "    decoded = tf.nn.sigmoid(decoded_raw)\n",
    "    \n",
    "    #discriminator\n",
    "    \n",
    "    d_fake_pred = discrim_model(decoded)\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_fake_pred, labels = tf.zeros_like(d_fake_pred)))\n",
    "    \n",
    "    d_real_pred = discrim_model(real_imgp)\n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_real_pred, labels = tf.ones_like(d_real_pred)))\n",
    "#     sent_pred = tf.concat([color,shape,direc],axis=1)\n",
    "    \n",
    "#     sent_cross_entropy = -1. *sentp *tf.log(sent_pred + 1e-30) - (1. - sentp) *tf.log(1. - sent_pred + 1e-30)\n",
    "#     sent_loss = tf.reduce_mean(sent_cross_entropy)\n",
    "\n",
    "    d_loss = \n",
    "    \n",
    "    loss = (4*dec_loss + sent_loss)/5\n",
    "       \n",
    "    return loss, decoded, dec_loss, sent_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs=8\n",
    "hs=64\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
    "y = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
    "real_imgp = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
    "sentp = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "loss, decoded, dec_loss, sent_loss = mk_nn_model(x, y=y, real_imgp=real_imgp, sentp=sentp, bs=bs)\n",
    "train_step = tf.train.AdamOptimizer(0.0001).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.load('sentences_64.npy')\n",
    "original_imgs = np.load('original_imgs_64.npy')\n",
    "translated_imgs = np.load('translated_imgs_64.npy')\n",
    "\n",
    "sentences_float = np.array(sentences, dtype=np.float32)\n",
    "original_imgs_float = np.array(original_imgs, dtype=np.float32)\n",
    "translated_imgs_float = np.array(translated_imgs, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# onesar = np.ones((55000, hs, hs, 3))\n",
    "# onesar[:,hs//2:,hs//2:,0:2] = 0\n",
    "\n",
    "# onesar = onesar.reshape(55000, hs*hs)\n",
    "# onesar = mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max = 95000\n",
    "\n",
    "input_img = original_imgs_float[:train_max] #np.array([original_imgs_float[0] for i in range(55000)])\n",
    "d_real_img = np.array(input_img)\n",
    "np.random.shuffle(d_real_img)\n",
    "output_img = translated_imgs_float[:train_max]\n",
    "sent_inp = sentences_float[:train_max]\n",
    "\n",
    "input_test = original_imgs_float[train_max:]\n",
    "output_test = translated_imgs_float[train_max:]\n",
    "sent_test = sentences_float[train_max:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "\n",
    "sess =  tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "  step, loss =       0: 0.09601\n",
      "  step, loss =     500: 0.08532\n",
      "  step, loss =    1000: 0.09882\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Training...')\n",
    "for i in range(100000):\n",
    "    if j+bs >= len(input_test):\n",
    "        j=0\n",
    "    batch_xs = input_img[j:j+bs]\n",
    "    batch_ys = output_img[j:j+bs]\n",
    "    batch_sent = sent_inp[j:j+bs]\n",
    "    batch_real_img = d_real_img[j:j+bs]\n",
    "    train_step.run({x: batch_xs, y: batch_ys, sentp: batch_sent, real_imgp = batch_real_img}, session=sess)\n",
    "    if i % 500 == 0:\n",
    "        train_loss= dec_loss.eval({x: batch_xs, y: batch_ys, sentp: batch_sent, real_imgp = batch_real_img}, session=sess)\n",
    "        print('  step, loss = %7d: %6.5f' % (i, train_loss))\n",
    "    j+=bs\n",
    "\n",
    "# generate decoded image with test data\n",
    "test_fd = {x: input_test[:bs], y: output_test[:bs], sentp: sent_test[:bs], real_imgp = d_real_img[:bs]}\n",
    "decoded_imgs = decoded.eval(test_fd, session=sess)\n",
    "print('loss (test) = ', dec_loss.eval(test_fd, session=sess))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "nbatches = 0.0\n",
    "decoded_imgs = []\n",
    "\n",
    "j=0\n",
    "while j+bs < len(input_test):\n",
    "    test_fd = {x: input_test[j:j+bs], y: output_test[j:j+bs], sentp: sent_test[j:j+bs]}\n",
    "    decoded_imgs.append(decoded.eval(test_fd, session=sess))\n",
    "    test_loss += dec_loss.eval(test_fd, session=sess)\n",
    "    \n",
    "    nbatches+=1\n",
    "    j+=bs\n",
    "# generate decoded image with test data\n",
    "\n",
    "test_loss /= nbatches\n",
    "decoded_imgs = np.array(decoded_imgs)\n",
    "\n",
    "print (test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = decoded_imgs.reshape((-1,64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x_test = input_test\n",
    "y_test = output_test\n",
    "n = bs  # how many digits we will display\n",
    "# plt.figure(figsize=(20, 4))\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "#     ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(np.array(x_test[i]*255, dtype=np.uint8))\n",
    "    plt.show()\n",
    "    plt.imshow(np.array(y_test[i]*255, dtype=np.uint8))\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    # display reconstruction\n",
    "#     ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(np.array(decoded_imgs[i]*255, dtype=np.uint8))\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#plt.show()\n",
    "plt.savefig('mnist_ae2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "#     print(shape)\n",
    "#     print(len(shape))\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "#         print(dim)\n",
    "        variable_parameters *= dim.value\n",
    "#     print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train808RemakeSentMoretrain/train808RemakeSentMoretrain.chkp'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver() \n",
    "saver.save(sess, 'train808RemakeSentMoretrain2/train808RemakeSentMoretrain2.chkp')\n",
    "\n",
    "# Then you'll be able to access the model:\n",
    "\n",
    "# sess = tf.Session()\n",
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess, 'filename.chkp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
